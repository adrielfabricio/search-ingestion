import os
from dotenv import load_dotenv
from search import get_vectorstore, create_rag_chain

load_dotenv()


def get_llm(provider: str = "openai"):
	"""Retorna inst√¢ncia do LLM configurado.

	Args:
		provider: Provedor de IA a ser usado. Op√ß√µes: "openai" ou "google" (padr√£o: "openai")

	Returns:
		Inst√¢ncia do LLM configurado
	"""
	provider = provider.lower()

	if provider == "openai":
		if not os.getenv("OPENAI_API_KEY"):
			raise ValueError("OPENAI_API_KEY n√£o encontrada no .env!")
		print("üîë Usando OpenAI LLM")
		from langchain_openai import ChatOpenAI
		return ChatOpenAI(
			model="gpt-5-nano",
			temperature=0.0,
			max_tokens=500
		)
	elif provider == "google":
		if not os.getenv("GOOGLE_API_KEY"):
			raise ValueError("GOOGLE_API_KEY n√£o encontrada no .env!")
		print("üîë Usando Google Gemini LLM")
		from langchain_google_genai import ChatGoogleGenerativeAI
		return ChatGoogleGenerativeAI(
			model="gemini-2.5-flash-lite",
			temperature=0.0,
			max_output_tokens=500
		)
	else:
		raise ValueError(f"Provider '{provider}' n√£o suportado! Use 'openai' ou 'google'.")


def main():
	"""Fun√ß√£o principal do chat CLI."""
	print("ü§ñ Chat de Busca Sem√¢ntica")
	print("=" * 50)
	print("Digite 'sair' para encerrar\n")

	try:
		# Inicializar LLM
		llm = get_llm()
		print("‚úÖ LLM inicializado com sucesso!\n")

		# Criar chain RAG
		chain = create_rag_chain(llm)
		vectorstore = get_vectorstore()
		print("‚úÖ Vectorstore conectado com sucesso!\n")

	except Exception as e:
		print(f"‚ùå Erro ao inicializar: {e}")
		return

	while True:
		try:
			# Receber pergunta do usu√°rio
			query = input("Fa√ßa sua pergunta: ").strip()

			# Verificar se quer sair
			if query.lower() in ['sair', 'exit', 'quit']:
				print("\nüëã Encerrando chat...")
				break

			# Verificar se pergunta n√£o est√° vazia
			if not query:
				print("‚ö†Ô∏è  Por favor, digite uma pergunta v√°lida.\n")
				continue

			# Buscar contexto
			print("\nüîç Buscando informa√ß√µes...")
			try:
				results = vectorstore.similarity_search_with_score(query, k=10)
				context = "\n\n".join([doc.page_content for doc, _ in results])
			except Exception as e:
				print(f"‚ùå Erro ao buscar informa√ß√µes: {e}\n")
				continue

			# Executar chain RAG
			print("üí≠ Gerando resposta...\n")
			try:
				response = chain.invoke({"context": context, "query": query})
				response_text = response["text"]
			except Exception as e:
				print(f"‚ùå Erro ao gerar resposta: {e}\n")
				continue

			# Exibir resposta formatada
			print("PERGUNTA:", query)
			print("RESPOSTA:", response_text)
			print("\n" + "-" * 50 + "\n")

		except KeyboardInterrupt:
			print("\n\nüëã Encerrando chat...")
			break
		except Exception as e:
			print(f"\n‚ùå Erro: {e}\n")
			continue


if __name__ == "__main__":
	main()
